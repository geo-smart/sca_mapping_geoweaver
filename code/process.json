[{
  "id" : "rgfp44",
  "name" : "data_preparation",
  "description" : "python",
  "code" : "# import functions and packages\nfrom functions_book_chapter_SCA import *\n\ndir_raster = './data/planet/20180528_181110_1025_3B_AnalyticMS_SR_clip.tif'\nplanet = rasterio.open(dir_raster).read()/10000\nplanet = np.where(planet[0,:,:] == 0, np.nan, planet) # the default nan data value is 0, replace with np.nan\n\nfig, axs = plt.subplots(2,2,figsize=(15,7.5))\nim1 = axs[0,0].imshow(planet[0,:,:],cmap='jet')\naxs[0,0].set_title(\"Surface reflectance of blue band\", fontsize=16)\n\nim2 = axs[0,1].imshow(planet[1,:,:], cmap='jet')\naxs[0,1].set_title(\"Surface reflectance of green band\", fontsize=16)\n\nim3 = axs[1,0].imshow(planet[2,:,:], cmap='jet')\naxs[1,0].set_title(\"Surface reflectance of red band\", fontsize=16)\n\nim4 = axs[1,1].imshow(planet[3,:,:], cmap='jet')\naxs[1,1].set_title(\"Surface reflectance of NIR band\", fontsize=16)\n\ncbar_ax = fig.add_axes([0.95, 0.15, 0.02, 0.7])\nfig.colorbar(im1, cax=cbar_ax)\n\n# read model input features and labels \ndata = pd.read_csv('./data/samples/sample_100K.csv', index_col = False)\nprint(\"Sample dimentions:\".format(), data.shape)\nprint(data.head())\nX = data[['blue','green','red','nir']]\ny = data['label']",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "4p0kit",
  "name" : "hyper_parameter_tuning",
  "description" : "python",
  "code" : "# prepare data \ndata = pd.read_csv('./data/samples/sample_10K.csv', index_col = False)\nprint(\"Sample dimentions:\".format(), data.shape)\ndata.head()\nX = data[['blue','green','red','nir']]\ny = data['label']\n\n# customize models with different sample sizes\nmodels = get_models_size()\nresults, names = list(), list()\nfor name, model in models.items():\n    # evaluate models using k-fold cross-validation\n    scores = evaluate_model(model, X, y)\n    results.append(scores)\n    names.append(name)\n    # print the mean and standard deviation of models \n    print('>%s   Mean Score: %.6f (Score SD: %.6f)' % ('Sample size: ' + str(int(float(name) * 10000)), scores.mean(), scores.std()))\n    \n# display model performance \nplt.figure(figsize=(10,5))\nplt.boxplot(results, labels=names, showmeans=True)\nplt.show()\n\n# customize models with different model feature sizes\nmodels = get_models_feature()\n# evaluate the models and store results\nresults, names = list(), list()\nfor name, model in models.items():\n    # evaluate models using k-fold cross-validation\n    scores = evaluate_model(model, X, y)\n    results.append(scores)\n    names.append(name)\n    # print the mean and standard deviation of models \n    # print('>%s %.3f (%.3f)' % (name, scores.mean(), scores.std()))\n    print('>%s   Mean Score: %.6f (Score SD: %.6f)' % ('Features: ' + name, scores.mean(), scores.std()))\n# display model performance \nplt.boxplot(results, labels=names, showmeans=True)\nplt.show()\n\n# customize models with different tree numbers\nmodels = get_models_tree()\n# evaluate the models and store results\nresults, names = list(), list()\nfor name, model in models.items():\n    # evaluate models using k-fold cross-validation\n    scores = evaluate_model(model, X, y)\n    results.append(scores)\n    names.append(name)\n    # print the mean and standard deviation of models \n    # print('>%s %.3f (%.3f)' % (name, scores.mean(), scores.std()))\n    print('>%s   Mean Score: %.6f (Score SD: %.6f)' % ('Tree numbers: ' + name, scores.mean(), scores.std()))\n# display model performance \nplt.boxplot(results, labels=names, showmeans=True)\nplt.show()\n\n# customize models with different tree depths\nmodels = get_models_depth()\n# evaluate the models and store results\nresults, names = list(), list()\nfor name, model in models.items():\n     # evaluate models using k-fold cross-validation\n    scores = evaluate_model(model, X, y)\n    results.append(scores)\n    names.append(name)\n    # print the mean and standard deviation of models \n    # print('>%s %.3f (%.3f)' % (name, scores.mean(), scores.std()))\n    print('>%s   Mean Score: %.6f (Score SD: %.6f)' % ('Tree Depth: ' + name, scores.mean(), scores.std()))\n# display model performance \nplt.figure(figsize=(10,5))\nplt.boxplot(results, labels=names, showmeans=True)\nplt.show()",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "xcw4h1",
  "name" : "model_evaluation",
  "description" : "python",
  "code" : "dir_aso = './data/ASO/ASO_3M_SD_USCATE_20180528_clip.tif'\nraso = rasterio.open(dir_aso,'r').read()\nraso = np.where(raso[0,:,:] < 0, np.nan, raso)\n\nth = 0.1 # using 10 cm threshold\nraso_binary = np.where(raso >= 0.1, 1, 0) # if the SD is higher than 10 cm, then snow; otherwise, no-snow\n\nfig, axs = plt.subplots(1,2,figsize=(16,6))\nim1 = axs[0].imshow(raso[0,:,:],cmap = 'Blues',vmin = 0, vmax = 5)\naxs[0].set_title('ASO snow depth', fontsize=16)\nfig.colorbar(im1, ax = axs[0], label = 'snow depth (meter)', extend = 'max')\n\nim2 = axs[1].imshow(raso_binary[0,:,:], cmap = 'gray', interpolation = 'none')\naxs[1].set_title('ASO snow cover (TH = 10 cm)', fontsize=16)\n\ndir_model = \"./models/random_forest_SCA_binary.joblib\"\n# load model\nmodel = joblib.load(dir_model)\n\ndf = pd.DataFrame()\ndf['obs'] = y_test\ndf['predict'] = model.predict(X_test)\n\n# Cross-tabulate predictions\nprint(pd.crosstab(df['obs'], df['predict'], margins=True))\nprint(calculate_metrics(df))\n\ndir_raster = './data/planet/20180528_181110_1025_3B_AnalyticMS_SR_clip.tif'\ndir_out = './data/SCA/'\nnodata_flag = 9\nrun_sca_prediction(dir_raster, dir_out, nodata_flag, model)\n\ndir_planet = './data/planet/20180528_181110_1025_3B_AnalyticMS_SR_clip.tif'\nr_na_flag = rasterio.open(dir_planet, 'r').read()\nr_planet = rasterio.open(dir_planet, 'r').read([4,3,2])/10000\n\ndir_sca = './data/SCA/20180528_181110_1025_3B_AnalyticMS_SR_clip_SCA.tif'\nr_sca = rasterio.open(dir_sca, 'r')\n\nfig, (ax1, ax2) = plt.subplots(1,2, figsize = (16,4))\nshow(r_planet, ax= ax1, cmap='jet', interpolation = 'none',title = 'Planet false color Image')\nshow(r_sca.read().squeeze(), ax= ax2, interpolation = 'none',title = 'Planet Snow Cover')\n\ndir_planet_ext = './data/GIS/extent/CATE_20180528_181110_img_ext.shp'\nwith fiona.open(dir_planet_ext, \"r\") as shapefile:\n    shapes = [feature[\"geometry\"] for feature in shapefile]\n    \ndir_aso = \"./data/ASO/ASO_3M_SD_USCATE_20180528_binary_clip.tif\"\nwith rasterio.open(dir_aso,'r') as src:\n    r_aso = rasterio.mask.mask(src, shapes, crop=True, filled = False)\n    \ndir_pred = './data/SCA/20180528_181110_1025_3B_AnalyticMS_SR_clip_SCA.tif'\nwith rasterio.open(dir_pred,'r') as src:\n    r_predict = rasterio.mask.mask(src, shapes, crop=True, filled = False)\n\ndir_watermask = './data/mask/waterbody_TB_UTM11_clip.tif'\nwith rasterio.open(dir_watermask,'r') as src:\n    r_watermask = rasterio.mask.mask(src, shapes, crop=True, filled = False)\n    \ndir_glaciermask = './data/mask/02_rgi60_WesternCanadaUS_hypso_TB_clip.tif'\nwith rasterio.open(dir_glaciermask,'r') as src:\n    r_glaciermask = rasterio.mask.mask(src, shapes, crop=True, filled = False)\n    \n    \ndf = pd.DataFrame()\ndf['predict'] = r_predict[0].ravel()\ndf['obs'] = r_aso[0].ravel()\ndf['watermask'] = r_watermask[0].ravel()\ndf['glaciermask'] = r_watermask[0].ravel()\n\n# remove NA data region, water bodies, and glaciers \ndf_mask = df[(df.predict >= 0) & (df.watermask != 0) & (df.glaciermask != 0)]\n# print(df)\n\nprint(\"overall model performance:\")\nprint(calculate_metrics(df_mask))\n\nfile_landcover = './data/ASO/ASO_3M_CHM_USCATB_20140827_binary_clip.tif' # 1 - forest, 0 open area\nwith rasterio.open(file_landcover,'r') as src:\n    r_landcover = rasterio.mask.mask(src, shapes, crop=True, filled = False)\n    \ndf['landcover'] = r_landcover[0].ravel()\n\ndf_mask = df[(df.predict >= 0) & (df.watermask != 0) & (df.glaciermask != 0)]\ndf_open = df_mask[df_mask.landcover == 0]\nprint(\"Model performance in open areas:\")\nprint(calculate_metrics(df_open))\n\ndf_forest = df_mask[df_mask.landcover == 1]\nprint(\"Model performance in forested areas:\")\nprint(calculate_metrics(df_forest))",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "8e59lt",
  "name" : "modeL-training",
  "description" : null,
  "code" : "import pandas as pd\n\n# read model input features and labels \ndata = pd.read_csv('./data/samples/sample_100K.csv', index_col = False)\nprint(\"Sample dimentions:\".format(), data.shape)\nprint(data.head())\nX = data[['blue','green','red','nir']]\ny = data['label']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.96,random_state=1)\n\n# define the model\nmodel = RandomForestClassifier(n_estimators=10, max_depth=10, max_features=4)\n\n# evaluate the model\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1000)\nn_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n# report model performance\nprint('Mean Score: %.6f (SD: %.6f)' % (n_scores.mean(),n_scores.std()))\n\n# the histogram of the scores\nn, bins, patches = plt.hist(n_scores, density=True, facecolor='blue', alpha=0.75)\nplt.text(0.91, 15, r'mean = ' + str(n_scores.mean().round(6)) + '  '+ 'SD = ' + str(n_scores.std().round(6)))\nplt.xlim(0.9, 1.01)\nplt.xlabel('Acuuracy')\nplt.ylabel('Probability (%)')\nplt.grid(True)\nplt.show()\n\nmodel.fit(X_train,y_train)\nresult = permutation_importance(model, X_train, y_train, n_repeats=1000, random_state=42, n_jobs=2)\nprint('Permutation importance - average:'.format(), X_train.columns)\nprint([round(i, 6) for i in result.importances_mean])\n\n# displace feature importance\nfig, ax = plt.subplots(figsize=(6,5))\nax.boxplot(result.importances.T)\nax.set_title(\"Permutation Importances\", fontsize = 16)\nax.set_xticklabels(labels=X_train.columns, fontsize=14)\nplt.show()\n\n# save model \ndir_model = \"./models/random_forest_SCA_binary.joblib\"\njoblib.dump(model, dir_model)",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "pi4g01",
  "name" : "functions_book_chapter_SCA",
  "description" : "python",
  "code" : "'''\nThis script includes all packages and functions required by the book chapter\n'''\n# evaluate random forest algorithm for classification\nfrom numpy import arange\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.inspection import permutation_importance\nfrom rasterio.plot import show\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sn\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport glob\nimport joblib\nimport rasterio\nimport pandas as pd\nimport matplotlib\n\n# clip the ASO data to planet extent\nimport fiona\nimport rasterio.mask\n\n\ndef calculate_metrics(df):\n    \n    # true positive and true negative\n    subdf = df[df.predict == df.obs]\n    TP = len(subdf[subdf.predict == 1].index)\n    TN = len(subdf[subdf.predict == 0].index)\n\n    # false positive and false negative\n    subdf = df[df.predict != df.obs]\n    FN = len(subdf[subdf.predict == 0].index)\n    FP = len(subdf[subdf.predict == 1].index)\n\n    precision = TP/(TP+FP)\n    recall = TP/(TP+FN)\n\n    sensitivity = TP/(TP+FN)\n    specificity = TN/(TN+FP)\n    balanced_accuracy = (sensitivity+specificity)/2\n    accuracy = (TP+TN)/(TP+TN+FP+FN)\n\n    f1 =  0 if precision + recall == 0 else (2 * precision * recall) / (precision + recall)\n    out = pd.DataFrame(data = {'precision': [precision], \n                               'recall':[recall], \n                               'f1':[f1],\n                               'balanced_accuracy':[balanced_accuracy], \n                               'accuracy':[accuracy]})\n    return out\n\n# the function used to predict binary snow cover\ndef run_sca_prediction(dir_raster, dir_out, nodata_flag, model):\n    \"\"\"\n    This function predicts binary snow cover for planet satellite images using \n    the pre-trained random forest model \n    \n    :param dir_raster: the directory or the file of planet images\n    :param dir_out: the directory where output snow cover images will be stored\n    :param nodata_flag: the value used to represent no data in the predicted snow cover image\n    defult value is 9.\n    model: the model used to predict snow cover\n    \n    \"\"\"\n    # if output directory not exist then creat the output directory\n    if not os.path.exists(dir_out): os.mkdir(dir_out)\n    \n    # if dir_raster is a directory, then find all images with 'SR' flag, meaning surface reflectance data\n    if os.path.isdir(dir_raster):\n        file_list = glob.glob(dir_raster + './**/*SR*.tif', recursive = True)\n    elif os.path.isfile(dir_raster):\n        file_list = [dir_raster]\n        \n    for f in file_list:\n        print('Start to predict:'.format(), os.path.basename(f))\n\n        with rasterio.open(f, 'r') as ds:\n            arr = ds.read()  # read all raster values\n\n        print(\"Image dimension:\".format(), arr.shape)  # \n        X_img = pd.DataFrame(arr.reshape([4,-1]).T)\n        X_img.columns = ['blue','green','red','nir']\n        X_img['nodata_flag'] = np.where(X_img['blue']==0, -1, 1)\n        \n        X_img = X_img/10000 # scale surface reflectance to 0-1\n        # run model prediction\n        y_img = model.predict(X_img.iloc[:,0:4])\n        \n        out_img = pd.DataFrame()\n        out_img['label'] = y_img\n        out_img['nodata_flag'] = X_img['nodata_flag']\n        out_img['label'] = np.where(out_img['nodata_flag'] == -1, nodata_flag, out_img['label'])\n        # Reshape our classification map\n        img_prediction = out_img['label'].to_numpy().reshape(arr[0,:, :].shape)\n\n        \n        file_out = dir_out + os.path.basename(f)[0:-4] + '_SCA.tif'\n        print(\"Save SCA map to: \".format(),file_out)\n        with rasterio.open(\n                        file_out, \"w\",\n                        driver = \"GTiff\",\n                        transform = ds.transform,\n                        dtype = rasterio.uint8,\n                        count = 1,\n                        crs = ds.crs,\n                        width = ds.width,\n                        height = ds.height) as dst:\n                    dst.write(img_prediction, indexes = 1)\n                \n                \n# model evaluation CA\ndef SCA_model_evaluation(dir_img_ext, dir_sca, dir_aso,flag_mask, dir_watermask, dir_glaciermask):\n    \"\"\"\n    This function evaluate snow cover mapping accuracy \n    \n    :param dir_img_ext: the ESRI shapefile of the image extent\n    :param dir_sca: the predicted SCA \n    :param dir_aso: the ASO snow depth\n    :param dir_watermask: water mask for Tuolumne CA; Only used for CA\n    :param dir_glaciermask: glacier mask for Tuolumne CA; Only used in CA\n    \n    \"\"\"\n    print('Start SCA Evaluation: --------')\n\n\n    with fiona.open(dir_img_ext, \"r\") as shapefile:\n        shapes = [feature[\"geometry\"] for feature in shapefile]\n\n    with rasterio.open(dir_aso) as src:\n        r_aso = rasterio.mask.mask(src, shapes, crop=True)\n\n    with rasterio.open(dir_sca) as src:\n        r_predict = rasterio.mask.mask(src, shapes, crop=True)\n\n\n    if flag_mask:\n        with rasterio.open(dir_watermask) as src:\n            r_watermask = rasterio.mask.mask(src, shapes, crop=True)\n\n        with rasterio.open(dir_glaciermask) as src:\n            r_glaciermask = rasterio.mask.mask(src, shapes, crop=True)\n\n    df = pd.DataFrame()\n    df['predict'] = r_predict[0].ravel()\n    df['obs'] = r_aso[0].ravel()\n    # get binary snow cover from ASO snow depth\n    df.obs = np.where(df.obs > 0.1, 1, 0)\n\n    if flag_mask:\n        df['watermask'] = r_watermask[0].ravel()\n        df['glaciermask'] = r_watermask[0].ravel()\n        # remove NA \n        df = df[(df.predict >= 0) & (df.watermask != 0) & (df.glaciermask != 0)]\n    else:\n        df = df[(df.predict >= 0)]\n    \n\n    print(\"overall model performance:\")\n    print(calculate_metrics(df))\n    \n    \ndef evaluate_model(model, X, y):\n    \"\"\"\n    Test model sensitivity \n    This function evaluates a given model using k-fold cross-validation\n    \"\"\"\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=100, random_state=1)\n    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n    return scores\n\n# get a list of models to evaluate\ndef get_models_size():\n    models = dict()\n    for i in np.concatenate((arange(0.01, 0.1, 0.01), arange(0.1, 1.0, 0.1))):\n        key = '%.2f' % i\n        if i == 1.0:\n            i = None\n        models[key] = RandomForestClassifier(max_samples=i)\n    return models\n\ndef get_models_feature():\n    models = dict()\n    for i in range(1,5):\n        models[str(i)] = RandomForestClassifier(max_features=i)\n    return models\n\ndef get_models_tree():\n    models = dict()\n    n_trees = [1,2,3,4,5,10,20,50,100,200,800,1000]\n    for n in n_trees:\n        models[str(n)] = RandomForestClassifier(n_estimators=n)\n    return models\n\ndef get_models_depth():\n    models = dict()\n    depths = [i for i in range(1,20)] + [None]\n    for n in depths:\n        models[str(n)] = RandomForestClassifier(max_depth=n)\n    return models\n",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
}]
