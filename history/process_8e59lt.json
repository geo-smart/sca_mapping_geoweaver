[{
  "history_id" : "tt8emd5m258",
  "history_input" : "import pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nimport matplotlib.pyplot as plt\nfrom sklearn.inspection import permutation_importance\nimport joblib\n\nhome_directory = os.path.expanduser('~')\nprint(\"Home Directory:\", home_directory)\n\n# read model input features and labels \ndata = pd.read_csv(f'{home_directory}/data/samples/sample_100K.csv', index_col = False)\nprint(\"Sample dimentions:\".format(), data.shape)\nprint(data.head())\nX = data[['blue','green','red','nir']]\ny = data['label']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.96,random_state=1)\n\n# define the model\nmodel = RandomForestClassifier(n_estimators=10, max_depth=10, max_features=4)\n\n# evaluate the model\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1000)\nn_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n# report model performance\nprint('Mean Score: %.6f (SD: %.6f)' % (n_scores.mean(),n_scores.std()))\n\n# the histogram of the scores\nn, bins, patches = plt.hist(n_scores, density=True, facecolor='blue', alpha=0.75)\nplt.text(0.91, 15, r'mean = ' + str(n_scores.mean().round(6)) + '  '+ 'SD = ' + str(n_scores.std().round(6)))\nplt.xlim(0.9, 1.01)\nplt.xlabel('Acuuracy')\nplt.ylabel('Probability (%)')\nplt.grid(True)\nplt.show()\n\nmodel.fit(X_train,y_train)\nresult = permutation_importance(model, X_train, y_train, n_repeats=1000, random_state=42, n_jobs=2)\nprint('Permutation importance - average:'.format(), X_train.columns)\nprint([round(i, 6) for i in result.importances_mean])\n\n# displace feature importance\nfig, ax = plt.subplots(figsize=(6,5))\nax.boxplot(result.importances.T)\nax.set_title(\"Permutation Importances\", fontsize = 16)\nax.set_xticklabels(labels=X_train.columns, fontsize=14)\n# plt.show()\n\n# save model \ndir_model = f\"{home_directory}/data/models/random_forest_SCA_binary.joblib\"\njoblib.dump(model, dir_model)\nprint(f\"The new model is saved to {dir_model}\")",
  "history_output" : "Home Directory: /Users/joe\nSample dimentions: (100000, 5)\n     blue   green     red     nir  label\n0  0.5948  0.4274  0.6514  0.6841      1\n1  0.1088  0.1296  0.1580  0.2639      0\n2  0.7735  0.5578  0.8296  0.7552      1\n3  0.1581  0.1793  0.2152  0.2700      0\n4  0.5916  0.4253  0.6499  0.6401      1\nMean Score: 0.998057 (SD: 0.002173)\nPermutation importance - average: Index(['blue', 'green', 'red', 'nir'], dtype='object')\n[0.520041, 0.000245, 0.000603, 0.000247]\nThe new model is saved to /Users/joe/data/models/random_forest_SCA_binary.joblib\n",
  "history_begin_time" : 1717476821202,
  "history_end_time" : 1717476910868,
  "history_notes" : null,
  "history_process" : "8e59lt",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "tbry08gopf8",
  "history_input" : "import pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nimport matplotlib.pyplot as plt\nfrom sklearn.inspection import permutation_importance\nimport joblib\n\nhome_directory = os.path.expanduser('~')\nprint(\"Home Directory:\", home_directory)\n\n# read model input features and labels \ndata = pd.read_csv(f'{home_directory}/data/samples/sample_100K.csv', index_col = False)\nprint(\"Sample dimentions:\".format(), data.shape)\nprint(data.head())\nX = data[['blue','green','red','nir']]\ny = data['label']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.96,random_state=1)\n\n# define the model\nmodel = RandomForestClassifier(n_estimators=10, max_depth=10, max_features=4)\n\n# evaluate the model\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1000)\nn_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n# report model performance\nprint('Mean Score: %.6f (SD: %.6f)' % (n_scores.mean(),n_scores.std()))\n\n# the histogram of the scores\nn, bins, patches = plt.hist(n_scores, density=True, facecolor='blue', alpha=0.75)\nplt.text(0.91, 15, r'mean = ' + str(n_scores.mean().round(6)) + '  '+ 'SD = ' + str(n_scores.std().round(6)))\nplt.xlim(0.9, 1.01)\nplt.xlabel('Acuuracy')\nplt.ylabel('Probability (%)')\nplt.grid(True)\nplt.show()\n\nmodel.fit(X_train,y_train)\nresult = permutation_importance(model, X_train, y_train, n_repeats=1000, random_state=42, n_jobs=2)\nprint('Permutation importance - average:'.format(), X_train.columns)\nprint([round(i, 6) for i in result.importances_mean])\n\n# displace feature importance\nfig, ax = plt.subplots(figsize=(6,5))\nax.boxplot(result.importances.T)\nax.set_title(\"Permutation Importances\", fontsize = 16)\nax.set_xticklabels(labels=X_train.columns, fontsize=14)\nplt.show()\n\n# save model \ndir_model = f\"{home_directory}/data/models/random_forest_SCA_binary.joblib\"\njoblib.dump(model, dir_model)",
  "history_output" : "Home Directory: /Users/joe\nSample dimentions: (100000, 5)\n     blue   green     red     nir  label\n0  0.5948  0.4274  0.6514  0.6841      1\n1  0.1088  0.1296  0.1580  0.2639      0\n2  0.7735  0.5578  0.8296  0.7552      1\n3  0.1581  0.1793  0.2152  0.2700      0\n4  0.5916  0.4253  0.6499  0.6401      1\nMean Score: 0.998045 (SD: 0.002134)\nPermutation importance - average: Index(['blue', 'green', 'red', 'nir'], dtype='object')\n[0.517897, 0.002379, 0.00048, 0.000121]\n",
  "history_begin_time" : 1717459964408,
  "history_end_time" : 1717476813717,
  "history_notes" : null,
  "history_process" : "8e59lt",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "yltrs18v2h0",
  "history_input" : "import pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nimport matplotlib.pyplot as plt\nfrom sklearn.inspection import permutation_importance\nimport joblib\n\nhome_directory = os.path.expanduser('~')\nprint(\"Home Directory:\", home_directory)\n\n# read model input features and labels \ndata = pd.read_csv(f'{home_directory}/data/samples/sample_100K.csv', index_col = False)\nprint(\"Sample dimentions:\".format(), data.shape)\nprint(data.head())\nX = data[['blue','green','red','nir']]\ny = data['label']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.96,random_state=1)\n\n# define the model\nmodel = RandomForestClassifier(n_estimators=10, max_depth=10, max_features=4)\n\n# evaluate the model\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1000)\nn_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n# report model performance\nprint('Mean Score: %.6f (SD: %.6f)' % (n_scores.mean(),n_scores.std()))\n\n# the histogram of the scores\nn, bins, patches = plt.hist(n_scores, density=True, facecolor='blue', alpha=0.75)\nplt.text(0.91, 15, r'mean = ' + str(n_scores.mean().round(6)) + '  '+ 'SD = ' + str(n_scores.std().round(6)))\nplt.xlim(0.9, 1.01)\nplt.xlabel('Acuuracy')\nplt.ylabel('Probability (%)')\nplt.grid(True)\nplt.show()\n\nmodel.fit(X_train,y_train)\nresult = permutation_importance(model, X_train, y_train, n_repeats=1000, random_state=42, n_jobs=2)\nprint('Permutation importance - average:'.format(), X_train.columns)\nprint([round(i, 6) for i in result.importances_mean])\n\n# displace feature importance\nfig, ax = plt.subplots(figsize=(6,5))\nax.boxplot(result.importances.T)\nax.set_title(\"Permutation Importances\", fontsize = 16)\nax.set_xticklabels(labels=X_train.columns, fontsize=14)\nplt.show()\n\n# save model \ndir_model = f\"{home_directory}/data/models/random_forest_SCA_binary.joblib\"\njoblib.dump(model, dir_model)",
  "history_output" : "Home Directory: /Users/joe\nSample dimentions: (100000, 5)\n     blue   green     red     nir  label\n0  0.5948  0.4274  0.6514  0.6841      1\n1  0.1088  0.1296  0.1580  0.2639      0\n2  0.7735  0.5578  0.8296  0.7552      1\n3  0.1581  0.1793  0.2152  0.2700      0\n4  0.5916  0.4253  0.6499  0.6401      1\nMean Score: 0.998055 (SD: 0.002155)\nPermutation importance - average: Index(['blue', 'green', 'red', 'nir'], dtype='object')\n[0.518376, -0.000123, 0.00025, 0.000401]\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/yltrs18v2h0/modeL-training.py\", line 55, in <module>\n    joblib.dump(model, dir_model)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py\", line 552, in dump\n    with open(filename, 'wb') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/Users/joe/data/models/random_forest_SCA_binary.joblib'\n",
  "history_begin_time" : 1717459644197,
  "history_end_time" : 1717459886570,
  "history_notes" : null,
  "history_process" : "8e59lt",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "r7KFuFcDnpaF",
  "history_input" : "import pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nimport matplotlib.pyplot as plt\nfrom sklearn.inspection import permutation_importance\nimport joblib\n\nhome_directory = os.path.expanduser('~')\nprint(\"Home Directory:\", home_directory)\n\n# read model input features and labels \ndata = pd.read_csv(f'{home_directory}/data/samples/sample_100K.csv', index_col = False)\nprint(\"Sample dimentions:\".format(), data.shape)\nprint(data.head())\nX = data[['blue','green','red','nir']]\ny = data['label']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.96,random_state=1)\n\n# define the model\nmodel = RandomForestClassifier(n_estimators=10, max_depth=10, max_features=4)\n\n# evaluate the model\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1000)\nn_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n# report model performance\nprint('Mean Score: %.6f (SD: %.6f)' % (n_scores.mean(),n_scores.std()))\n\n# the histogram of the scores\nn, bins, patches = plt.hist(n_scores, density=True, facecolor='blue', alpha=0.75)\nplt.text(0.91, 15, r'mean = ' + str(n_scores.mean().round(6)) + '  '+ 'SD = ' + str(n_scores.std().round(6)))\nplt.xlim(0.9, 1.01)\nplt.xlabel('Acuuracy')\nplt.ylabel('Probability (%)')\nplt.grid(True)\nplt.show()\n\nmodel.fit(X_train,y_train)\nresult = permutation_importance(model, X_train, y_train, n_repeats=1000, random_state=42, n_jobs=2)\nprint('Permutation importance - average:'.format(), X_train.columns)\nprint([round(i, 6) for i in result.importances_mean])\n\n# displace feature importance\nfig, ax = plt.subplots(figsize=(6,5))\nax.boxplot(result.importances.T)\nax.set_title(\"Permutation Importances\", fontsize = 16)\nax.set_xticklabels(labels=X_train.columns, fontsize=14)\nplt.show()\n\n# save model \ndir_model = f\"{home_directory}/data/models/random_forest_SCA_binary.joblib\"\njoblib.dump(model, dir_model)",
  "history_output" : "Home Directory: /Users/joe\nSample dimentions: (100000, 5)\n     blue   green     red     nir  label\n0  0.5948  0.4274  0.6514  0.6841      1\n1  0.1088  0.1296  0.1580  0.2639      0\n2  0.7735  0.5578  0.8296  0.7552      1\n3  0.1581  0.1793  0.2152  0.2700      0\n4  0.5916  0.4253  0.6499  0.6401      1\nMean Score: 0.998050 (SD: 0.002163)\nPermutation importance - average: Index(['blue', 'green', 'red', 'nir'], dtype='object')\n[0.518922, 0.000498, 0.000495, 0.012608]\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/r7KFuFcDnpaF/modeL-training.py\", line 55, in <module>\n    joblib.dump(model, dir_model)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py\", line 552, in dump\n    with open(filename, 'wb') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/Users/joe/data/models/random_forest_SCA_binary.joblib'\n",
  "history_begin_time" : 1717396668355,
  "history_end_time" : 1717396751375,
  "history_notes" : null,
  "history_process" : "8e59lt",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "snwbzOTKQQmY",
  "history_input" : "import pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nimport matplotlib.pyplot as plt\nfrom sklearn.inspection import permutation_importance\nimport joblib\n\nhome_directory = os.path.expanduser('~')\nprint(\"Home Directory:\", home_directory)\n\n# read model input features and labels \ndata = pd.read_csv(f'{home_directory}/data/samples/sample_100K.csv', index_col = False)\nprint(\"Sample dimentions:\".format(), data.shape)\nprint(data.head())\nX = data[['blue','green','red','nir']]\ny = data['label']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.96,random_state=1)\n\n# define the model\nmodel = RandomForestClassifier(n_estimators=10, max_depth=10, max_features=4)\n\n# evaluate the model\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1000)\nn_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n# report model performance\nprint('Mean Score: %.6f (SD: %.6f)' % (n_scores.mean(),n_scores.std()))\n\n# the histogram of the scores\nn, bins, patches = plt.hist(n_scores, density=True, facecolor='blue', alpha=0.75)\nplt.text(0.91, 15, r'mean = ' + str(n_scores.mean().round(6)) + '  '+ 'SD = ' + str(n_scores.std().round(6)))\nplt.xlim(0.9, 1.01)\nplt.xlabel('Acuuracy')\nplt.ylabel('Probability (%)')\nplt.grid(True)\nplt.show()\n\nmodel.fit(X_train,y_train)\nresult = permutation_importance(model, X_train, y_train, n_repeats=1000, random_state=42, n_jobs=2)\nprint('Permutation importance - average:'.format(), X_train.columns)\nprint([round(i, 6) for i in result.importances_mean])\n\n# displace feature importance\nfig, ax = plt.subplots(figsize=(6,5))\nax.boxplot(result.importances.T)\nax.set_title(\"Permutation Importances\", fontsize = 16)\nax.set_xticklabels(labels=X_train.columns, fontsize=14)\nplt.show()\n\n# save model \ndir_model = f\"{home_directory}/models/random_forest_SCA_binary.joblib\"\njoblib.dump(model, dir_model)",
  "history_output" : "Home Directory: /Users/joe\nSample dimentions: (100000, 5)\n     blue   green     red     nir  label\n0  0.5948  0.4274  0.6514  0.6841      1\n1  0.1088  0.1296  0.1580  0.2639      0\n2  0.7735  0.5578  0.8296  0.7552      1\n3  0.1581  0.1793  0.2152  0.2700      0\n4  0.5916  0.4253  0.6499  0.6401      1\nMean Score: 0.998054 (SD: 0.002175)\nPermutation importance - average: Index(['blue', 'green', 'red', 'nir'], dtype='object')\n[0.5164, 0.000132, 0.001739, 0.000653]\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/snwbzOTKQQmY/modeL-training.py\", line 55, in <module>\n    joblib.dump(model, dir_model)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py\", line 552, in dump\n    with open(filename, 'wb') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/Users/joe/models/random_forest_SCA_binary.joblib'\n",
  "history_begin_time" : 1717396539819,
  "history_end_time" : 1717396641754,
  "history_notes" : null,
  "history_process" : "8e59lt",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "x7xvaA4SM1yl",
  "history_input" : "import pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nimport matplotlib.pyplot as plt\nfrom sklearn.inspection import permutation_importance\n\nhome_directory = os.path.expanduser('~')\nprint(\"Home Directory:\", home_directory)\n\n# read model input features and labels \ndata = pd.read_csv(f'{home_directory}/data/samples/sample_100K.csv', index_col = False)\nprint(\"Sample dimentions:\".format(), data.shape)\nprint(data.head())\nX = data[['blue','green','red','nir']]\ny = data['label']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.96,random_state=1)\n\n# define the model\nmodel = RandomForestClassifier(n_estimators=10, max_depth=10, max_features=4)\n\n# evaluate the model\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1000)\nn_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n# report model performance\nprint('Mean Score: %.6f (SD: %.6f)' % (n_scores.mean(),n_scores.std()))\n\n# the histogram of the scores\nn, bins, patches = plt.hist(n_scores, density=True, facecolor='blue', alpha=0.75)\nplt.text(0.91, 15, r'mean = ' + str(n_scores.mean().round(6)) + '  '+ 'SD = ' + str(n_scores.std().round(6)))\nplt.xlim(0.9, 1.01)\nplt.xlabel('Acuuracy')\nplt.ylabel('Probability (%)')\nplt.grid(True)\nplt.show()\n\nmodel.fit(X_train,y_train)\nresult = permutation_importance(model, X_train, y_train, n_repeats=1000, random_state=42, n_jobs=2)\nprint('Permutation importance - average:'.format(), X_train.columns)\nprint([round(i, 6) for i in result.importances_mean])\n\n# displace feature importance\nfig, ax = plt.subplots(figsize=(6,5))\nax.boxplot(result.importances.T)\nax.set_title(\"Permutation Importances\", fontsize = 16)\nax.set_xticklabels(labels=X_train.columns, fontsize=14)\nplt.show()\n\n# save model \ndir_model = f\"{home_directory}/models/random_forest_SCA_binary.joblib\"\njoblib.dump(model, dir_model)",
  "history_output" : "Home Directory: /Users/joe\nSample dimentions: (100000, 5)\n     blue   green     red     nir  label\n0  0.5948  0.4274  0.6514  0.6841      1\n1  0.1088  0.1296  0.1580  0.2639      0\n2  0.7735  0.5578  0.8296  0.7552      1\n3  0.1581  0.1793  0.2152  0.2700      0\n4  0.5916  0.4253  0.6499  0.6401      1\nMean Score: 0.998066 (SD: 0.002118)\nPermutation importance - average: Index(['blue', 'green', 'red', 'nir'], dtype='object')\n[0.518269, -0.000238, 0.000599, 0.000719]\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/x7xvaA4SM1yl/modeL-training.py\", line 54, in <module>\n    joblib.dump(model, dir_model)\nNameError: name 'joblib' is not defined\n",
  "history_begin_time" : 1717396413304,
  "history_end_time" : 1717396522416,
  "history_notes" : null,
  "history_process" : "8e59lt",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "qO5y19ASFW3b",
  "history_input" : "import pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nimport matplotlib.pyplot as plt\nfrom sklearn.inspection import permutation_importance\n\nhome_directory = os.path.expanduser('~')\nprint(\"Home Directory:\", home_directory)\n\n# read model input features and labels \ndata = pd.read_csv(f'{home_directory}/data/samples/sample_100K.csv', index_col = False)\nprint(\"Sample dimentions:\".format(), data.shape)\nprint(data.head())\nX = data[['blue','green','red','nir']]\ny = data['label']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.96,random_state=1)\n\n# define the model\nmodel = RandomForestClassifier(n_estimators=10, max_depth=10, max_features=4)\n\n# evaluate the model\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1000)\nn_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n# report model performance\nprint('Mean Score: %.6f (SD: %.6f)' % (n_scores.mean(),n_scores.std()))\n\n# the histogram of the scores\nn, bins, patches = plt.hist(n_scores, density=True, facecolor='blue', alpha=0.75)\nplt.text(0.91, 15, r'mean = ' + str(n_scores.mean().round(6)) + '  '+ 'SD = ' + str(n_scores.std().round(6)))\nplt.xlim(0.9, 1.01)\nplt.xlabel('Acuuracy')\nplt.ylabel('Probability (%)')\nplt.grid(True)\nplt.show()\n\nmodel.fit(X_train,y_train)\nresult = permutation_importance(model, X_train, y_train, n_repeats=1000, random_state=42, n_jobs=2)\nprint('Permutation importance - average:'.format(), X_train.columns)\nprint([round(i, 6) for i in result.importances_mean])\n\n# displace feature importance\nfig, ax = plt.subplots(figsize=(6,5))\nax.boxplot(result.importances.T)\nax.set_title(\"Permutation Importances\", fontsize = 16)\nax.set_xticklabels(labels=X_train.columns, fontsize=14)\nplt.show()\n\n# save model \ndir_model = f\"{home_directory}/models/random_forest_SCA_binary.joblib\"\njoblib.dump(model, dir_model)",
  "history_output" : "Home Directory: /Users/joe\nSample dimentions: (100000, 5)\n     blue   green     red     nir  label\n0  0.5948  0.4274  0.6514  0.6841      1\n1  0.1088  0.1296  0.1580  0.2639      0\n2  0.7735  0.5578  0.8296  0.7552      1\n3  0.1581  0.1793  0.2152  0.2700      0\n",
  "history_begin_time" : 1717396341823,
  "history_end_time" : 1717396410657,
  "history_notes" : null,
  "history_process" : "8e59lt",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "32YLVQViTMSV",
  "history_input" : "import pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nimport matplotlib.pyplot as plt\nfrom sklearn.inspection import permutation_importance\n\nhome_directory = os.path.expanduser('~')\nprint(\"Home Directory:\", home_directory)\n\n# read model input features and labels \ndata = pd.read_csv(f'{home_directory}/data/samples/sample_100K.csv', index_col = False)\nprint(\"Sample dimentions:\".format(), data.shape)\nprint(data.head())\nX = data[['blue','green','red','nir']]\ny = data['label']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.96,random_state=1)\n\n# define the model\nmodel = RandomForestClassifier(n_estimators=10, max_depth=10, max_features=4)\n\n# evaluate the model\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1000)\nn_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n# report model performance\nprint('Mean Score: %.6f (SD: %.6f)' % (n_scores.mean(),n_scores.std()))\n\n# the histogram of the scores\nn, bins, patches = plt.hist(n_scores, density=True, facecolor='blue', alpha=0.75)\nplt.text(0.91, 15, r'mean = ' + str(n_scores.mean().round(6)) + '  '+ 'SD = ' + str(n_scores.std().round(6)))\nplt.xlim(0.9, 1.01)\nplt.xlabel('Acuuracy')\nplt.ylabel('Probability (%)')\nplt.grid(True)\nplt.show()\n\nmodel.fit(X_train,y_train)\nresult = permutation_importance(model, X_train, y_train, n_repeats=1000, random_state=42, n_jobs=2)\nprint('Permutation importance - average:'.format(), X_train.columns)\nprint([round(i, 6) for i in result.importances_mean])\n\n# displace feature importance\nfig, ax = plt.subplots(figsize=(6,5))\nax.boxplot(result.importances.T)\nax.set_title(\"Permutation Importances\", fontsize = 16)\nax.set_xticklabels(labels=X_train.columns, fontsize=14)\nplt.show()\n\n# save model \ndir_model = f\"{home_directory}/models/random_forest_SCA_binary.joblib\"\njoblib.dump(model, dir_model)",
  "history_output" : "Home Directory: /Users/joe\nSample dimentions: (100000, 5)\n     blue   green     red     nir  label\n0  0.5948  0.4274  0.6514  0.6841      1\n1  0.1088  0.1296  0.1580  0.2639      0\n2  0.7735  0.5578  0.8296  0.7552      1\n3  0.1581  0.1793  0.2152  0.2700      0\n4  0.5916  0.4253  0.6499  0.6401      1\n",
  "history_begin_time" : 1717396340300,
  "history_end_time" : 1717396409392,
  "history_notes" : null,
  "history_process" : "8e59lt",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "WODAoM4CpJ3m",
  "history_input" : "import pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nimport matplotlib.pyplot as plt\n\nhome_directory = os.path.expanduser('~')\nprint(\"Home Directory:\", home_directory)\n\n# read model input features and labels \ndata = pd.read_csv(f'{home_directory}/data/samples/sample_100K.csv', index_col = False)\nprint(\"Sample dimentions:\".format(), data.shape)\nprint(data.head())\nX = data[['blue','green','red','nir']]\ny = data['label']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.96,random_state=1)\n\n# define the model\nmodel = RandomForestClassifier(n_estimators=10, max_depth=10, max_features=4)\n\n# evaluate the model\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1000)\nn_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n# report model performance\nprint('Mean Score: %.6f (SD: %.6f)' % (n_scores.mean(),n_scores.std()))\n\n# the histogram of the scores\nn, bins, patches = plt.hist(n_scores, density=True, facecolor='blue', alpha=0.75)\nplt.text(0.91, 15, r'mean = ' + str(n_scores.mean().round(6)) + '  '+ 'SD = ' + str(n_scores.std().round(6)))\nplt.xlim(0.9, 1.01)\nplt.xlabel('Acuuracy')\nplt.ylabel('Probability (%)')\nplt.grid(True)\nplt.show()\n\nmodel.fit(X_train,y_train)\nresult = permutation_importance(model, X_train, y_train, n_repeats=1000, random_state=42, n_jobs=2)\nprint('Permutation importance - average:'.format(), X_train.columns)\nprint([round(i, 6) for i in result.importances_mean])\n\n# displace feature importance\nfig, ax = plt.subplots(figsize=(6,5))\nax.boxplot(result.importances.T)\nax.set_title(\"Permutation Importances\", fontsize = 16)\nax.set_xticklabels(labels=X_train.columns, fontsize=14)\nplt.show()\n\n# save model \ndir_model = f\"{home_directory}/models/random_forest_SCA_binary.joblib\"\njoblib.dump(model, dir_model)",
  "history_output" : "Home Directory: /Users/joe\nSample dimentions: (100000, 5)\n     blue   green     red     nir  label\n0  0.5948  0.4274  0.6514  0.6841      1\n1  0.1088  0.1296  0.1580  0.2639      0\n2  0.7735  0.5578  0.8296  0.7552      1\n3  0.1581  0.1793  0.2152  0.2700      0\n4  0.5916  0.4253  0.6499  0.6401      1\nMean Score: 0.998048 (SD: 0.002154)\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/WODAoM4CpJ3m/modeL-training.py\", line 40, in <module>\n    result = permutation_importance(model, X_train, y_train, n_repeats=1000, random_state=42, n_jobs=2)\nNameError: name 'permutation_importance' is not defined\n",
  "history_begin_time" : 1717396217957,
  "history_end_time" : 1717396329569,
  "history_notes" : null,
  "history_process" : "8e59lt",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "QGeLwTSnCr1O",
  "history_input" : "import pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import cross_val_score\n\nhome_directory = os.path.expanduser('~')\nprint(\"Home Directory:\", home_directory)\n\n# read model input features and labels \ndata = pd.read_csv(f'{home_directory}/data/samples/sample_100K.csv', index_col = False)\nprint(\"Sample dimentions:\".format(), data.shape)\nprint(data.head())\nX = data[['blue','green','red','nir']]\ny = data['label']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.96,random_state=1)\n\n# define the model\nmodel = RandomForestClassifier(n_estimators=10, max_depth=10, max_features=4)\n\n# evaluate the model\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1000)\nn_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n# report model performance\nprint('Mean Score: %.6f (SD: %.6f)' % (n_scores.mean(),n_scores.std()))\n\n# the histogram of the scores\nn, bins, patches = plt.hist(n_scores, density=True, facecolor='blue', alpha=0.75)\nplt.text(0.91, 15, r'mean = ' + str(n_scores.mean().round(6)) + '  '+ 'SD = ' + str(n_scores.std().round(6)))\nplt.xlim(0.9, 1.01)\nplt.xlabel('Acuuracy')\nplt.ylabel('Probability (%)')\nplt.grid(True)\nplt.show()\n\nmodel.fit(X_train,y_train)\nresult = permutation_importance(model, X_train, y_train, n_repeats=1000, random_state=42, n_jobs=2)\nprint('Permutation importance - average:'.format(), X_train.columns)\nprint([round(i, 6) for i in result.importances_mean])\n\n# displace feature importance\nfig, ax = plt.subplots(figsize=(6,5))\nax.boxplot(result.importances.T)\nax.set_title(\"Permutation Importances\", fontsize = 16)\nax.set_xticklabels(labels=X_train.columns, fontsize=14)\nplt.show()\n\n# save model \ndir_model = f\"{home_directory}/models/random_forest_SCA_binary.joblib\"\njoblib.dump(model, dir_model)",
  "history_output" : "Home Directory: /Users/joe\nSample dimentions: (100000, 5)\n     blue   green     red     nir  label\n0  0.5948  0.4274  0.6514  0.6841      1\n1  0.1088  0.1296  0.1580  0.2639      0\n2  0.7735  0.5578  0.8296  0.7552      1\n3  0.1581  0.1793  0.2152  0.2700      0\n4  0.5916  0.4253  0.6499  0.6401      1\nMean Score: 0.998048 (SD: 0.002149)\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/QGeLwTSnCr1O/modeL-training.py\", line 30, in <module>\n    n, bins, patches = plt.hist(n_scores, density=True, facecolor='blue', alpha=0.75)\nNameError: name 'plt' is not defined\n",
  "history_begin_time" : 1717396138186,
  "history_end_time" : 1717396194046,
  "history_notes" : null,
  "history_process" : "8e59lt",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "3RdbJyYDQ1mw",
  "history_input" : "import pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\nhome_directory = os.path.expanduser('~')\nprint(\"Home Directory:\", home_directory)\n\n# read model input features and labels \ndata = pd.read_csv(f'{home_directory}/data/samples/sample_100K.csv', index_col = False)\nprint(\"Sample dimentions:\".format(), data.shape)\nprint(data.head())\nX = data[['blue','green','red','nir']]\ny = data['label']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.96,random_state=1)\n\n# define the model\nmodel = RandomForestClassifier(n_estimators=10, max_depth=10, max_features=4)\n\n# evaluate the model\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1000)\nn_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n# report model performance\nprint('Mean Score: %.6f (SD: %.6f)' % (n_scores.mean(),n_scores.std()))\n\n# the histogram of the scores\nn, bins, patches = plt.hist(n_scores, density=True, facecolor='blue', alpha=0.75)\nplt.text(0.91, 15, r'mean = ' + str(n_scores.mean().round(6)) + '  '+ 'SD = ' + str(n_scores.std().round(6)))\nplt.xlim(0.9, 1.01)\nplt.xlabel('Acuuracy')\nplt.ylabel('Probability (%)')\nplt.grid(True)\nplt.show()\n\nmodel.fit(X_train,y_train)\nresult = permutation_importance(model, X_train, y_train, n_repeats=1000, random_state=42, n_jobs=2)\nprint('Permutation importance - average:'.format(), X_train.columns)\nprint([round(i, 6) for i in result.importances_mean])\n\n# displace feature importance\nfig, ax = plt.subplots(figsize=(6,5))\nax.boxplot(result.importances.T)\nax.set_title(\"Permutation Importances\", fontsize = 16)\nax.set_xticklabels(labels=X_train.columns, fontsize=14)\nplt.show()\n\n# save model \ndir_model = f\"{home_directory}/models/random_forest_SCA_binary.joblib\"\njoblib.dump(model, dir_model)",
  "history_output" : "Home Directory: /Users/joe\nSample dimentions: (100000, 5)\n     blue   green     red     nir  label\n0  0.5948  0.4274  0.6514  0.6841      1\n1  0.1088  0.1296  0.1580  0.2639      0\n2  0.7735  0.5578  0.8296  0.7552      1\n3  0.1581  0.1793  0.2152  0.2700      0\n4  0.5916  0.4253  0.6499  0.6401      1\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/3RdbJyYDQ1mw/modeL-training.py\", line 22, in <module>\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1000)\nNameError: name 'RepeatedStratifiedKFold' is not defined\n",
  "history_begin_time" : 1717396123553,
  "history_end_time" : 1717396124515,
  "history_notes" : null,
  "history_process" : "8e59lt",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "oQgNQUkhMDeL",
  "history_input" : "import pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split\n\nhome_directory = os.path.expanduser('~')\nprint(\"Home Directory:\", home_directory)\n\n# read model input features and labels \ndata = pd.read_csv(f'{home_directory}/data/samples/sample_100K.csv', index_col = False)\nprint(\"Sample dimentions:\".format(), data.shape)\nprint(data.head())\nX = data[['blue','green','red','nir']]\ny = data['label']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.96,random_state=1)\n\n# define the model\nmodel = RandomForestClassifier(n_estimators=10, max_depth=10, max_features=4)\n\n# evaluate the model\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1000)\nn_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n# report model performance\nprint('Mean Score: %.6f (SD: %.6f)' % (n_scores.mean(),n_scores.std()))\n\n# the histogram of the scores\nn, bins, patches = plt.hist(n_scores, density=True, facecolor='blue', alpha=0.75)\nplt.text(0.91, 15, r'mean = ' + str(n_scores.mean().round(6)) + '  '+ 'SD = ' + str(n_scores.std().round(6)))\nplt.xlim(0.9, 1.01)\nplt.xlabel('Acuuracy')\nplt.ylabel('Probability (%)')\nplt.grid(True)\nplt.show()\n\nmodel.fit(X_train,y_train)\nresult = permutation_importance(model, X_train, y_train, n_repeats=1000, random_state=42, n_jobs=2)\nprint('Permutation importance - average:'.format(), X_train.columns)\nprint([round(i, 6) for i in result.importances_mean])\n\n# displace feature importance\nfig, ax = plt.subplots(figsize=(6,5))\nax.boxplot(result.importances.T)\nax.set_title(\"Permutation Importances\", fontsize = 16)\nax.set_xticklabels(labels=X_train.columns, fontsize=14)\nplt.show()\n\n# save model \ndir_model = f\"{home_directory}/models/random_forest_SCA_binary.joblib\"\njoblib.dump(model, dir_model)",
  "history_output" : "Home Directory: /Users/joe\nSample dimentions: (100000, 5)\n     blue   green     red     nir  label\n0  0.5948  0.4274  0.6514  0.6841      1\n1  0.1088  0.1296  0.1580  0.2639      0\n2  0.7735  0.5578  0.8296  0.7552      1\n3  0.1581  0.1793  0.2152  0.2700      0\n4  0.5916  0.4253  0.6499  0.6401      1\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/oQgNQUkhMDeL/modeL-training.py\", line 18, in <module>\n    model = RandomForestClassifier(n_estimators=10, max_depth=10, max_features=4)\nNameError: name 'RandomForestClassifier' is not defined\n",
  "history_begin_time" : 1717396105389,
  "history_end_time" : 1717396106340,
  "history_notes" : null,
  "history_process" : "8e59lt",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "uj00g5d0q5v",
  "history_input" : "import pandas as pd\nimport os\n\nhome_directory = os.path.expanduser('~')\nprint(\"Home Directory:\", home_directory)\n\n# read model input features and labels \ndata = pd.read_csv(f'{home_directory}/data/samples/sample_100K.csv', index_col = False)\nprint(\"Sample dimentions:\".format(), data.shape)\nprint(data.head())\nX = data[['blue','green','red','nir']]\ny = data['label']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.96,random_state=1)\n\n# define the model\nmodel = RandomForestClassifier(n_estimators=10, max_depth=10, max_features=4)\n\n# evaluate the model\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1000)\nn_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n# report model performance\nprint('Mean Score: %.6f (SD: %.6f)' % (n_scores.mean(),n_scores.std()))\n\n# the histogram of the scores\nn, bins, patches = plt.hist(n_scores, density=True, facecolor='blue', alpha=0.75)\nplt.text(0.91, 15, r'mean = ' + str(n_scores.mean().round(6)) + '  '+ 'SD = ' + str(n_scores.std().round(6)))\nplt.xlim(0.9, 1.01)\nplt.xlabel('Acuuracy')\nplt.ylabel('Probability (%)')\nplt.grid(True)\nplt.show()\n\nmodel.fit(X_train,y_train)\nresult = permutation_importance(model, X_train, y_train, n_repeats=1000, random_state=42, n_jobs=2)\nprint('Permutation importance - average:'.format(), X_train.columns)\nprint([round(i, 6) for i in result.importances_mean])\n\n# displace feature importance\nfig, ax = plt.subplots(figsize=(6,5))\nax.boxplot(result.importances.T)\nax.set_title(\"Permutation Importances\", fontsize = 16)\nax.set_xticklabels(labels=X_train.columns, fontsize=14)\nplt.show()\n\n# save model \ndir_model = f\"{home_directory}/models/random_forest_SCA_binary.joblib\"\njoblib.dump(model, dir_model)",
  "history_output" : "Home Directory: /Users/joe\nSample dimentions: (100000, 5)\n     blue   green     red     nir  label\n0  0.5948  0.4274  0.6514  0.6841      1\n1  0.1088  0.1296  0.1580  0.2639      0\n2  0.7735  0.5578  0.8296  0.7552      1\n3  0.1581  0.1793  0.2152  0.2700      0\n4  0.5916  0.4253  0.6499  0.6401      1\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/uj00g5d0q5v/modeL-training.py\", line 14, in <module>\n    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.96,random_state=1)\nNameError: name 'train_test_split' is not defined\n",
  "history_begin_time" : 1717396051132,
  "history_end_time" : 1717396051699,
  "history_notes" : null,
  "history_process" : "8e59lt",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "t3c8uslvlz4",
  "history_input" : "import pandas as pd\nimport os\n\nhome_directory = os.path.expanduser('~')\nprint(\"Home Directory:\", home_directory)\n\n# read model input features and labels \ndata = pd.read_csv(f'{home_directory}/data/samples/sample_100K.csv', index_col = False)\nprint(\"Sample dimentions:\".format(), data.shape)\nprint(data.head())\nX = data[['blue','green','red','nir']]\ny = data['label']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.96,random_state=1)\n\n# define the model\nmodel = RandomForestClassifier(n_estimators=10, max_depth=10, max_features=4)\n\n# evaluate the model\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1000)\nn_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n# report model performance\nprint('Mean Score: %.6f (SD: %.6f)' % (n_scores.mean(),n_scores.std()))\n\n# the histogram of the scores\nn, bins, patches = plt.hist(n_scores, density=True, facecolor='blue', alpha=0.75)\nplt.text(0.91, 15, r'mean = ' + str(n_scores.mean().round(6)) + '  '+ 'SD = ' + str(n_scores.std().round(6)))\nplt.xlim(0.9, 1.01)\nplt.xlabel('Acuuracy')\nplt.ylabel('Probability (%)')\nplt.grid(True)\nplt.show()\n\nmodel.fit(X_train,y_train)\nresult = permutation_importance(model, X_train, y_train, n_repeats=1000, random_state=42, n_jobs=2)\nprint('Permutation importance - average:'.format(), X_train.columns)\nprint([round(i, 6) for i in result.importances_mean])\n\n# displace feature importance\nfig, ax = plt.subplots(figsize=(6,5))\nax.boxplot(result.importances.T)\nax.set_title(\"Permutation Importances\", fontsize = 16)\nax.set_xticklabels(labels=X_train.columns, fontsize=14)\nplt.show()\n\n# save model \ndir_model = f\"{home_directory}/models/random_forest_SCA_binary.joblib\"\njoblib.dump(model, dir_model)",
  "history_output" : "Home Directory: /Users/joe\nSample dimentions: (100000, 5)\n     blue   green     red     nir  label\n0  0.5948  0.4274  0.6514  0.6841      1\n1  0.1088  0.1296  0.1580  0.2639      0\n2  0.7735  0.5578  0.8296  0.7552      1\n3  0.1581  0.1793  0.2152  0.2700      0\n4  0.5916  0.4253  0.6499  0.6401      1\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/t3c8uslvlz4/modeL-training.py\", line 14, in <module>\n    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.96,random_state=1)\nNameError: name 'train_test_split' is not defined\n",
  "history_begin_time" : 1717395927524,
  "history_end_time" : 1717395928060,
  "history_notes" : null,
  "history_process" : "8e59lt",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "m2tvefpftuh",
  "history_input" : "import pandas as pd\n\nhome_directory = os.path.expanduser('~')\nprint(\"Home Directory:\", home_directory)\n\n# read model input features and labels \ndata = pd.read_csv(f'{home_directory}/data/samples/sample_100K.csv', index_col = False)\nprint(\"Sample dimentions:\".format(), data.shape)\nprint(data.head())\nX = data[['blue','green','red','nir']]\ny = data['label']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.96,random_state=1)\n\n# define the model\nmodel = RandomForestClassifier(n_estimators=10, max_depth=10, max_features=4)\n\n# evaluate the model\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1000)\nn_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n# report model performance\nprint('Mean Score: %.6f (SD: %.6f)' % (n_scores.mean(),n_scores.std()))\n\n# the histogram of the scores\nn, bins, patches = plt.hist(n_scores, density=True, facecolor='blue', alpha=0.75)\nplt.text(0.91, 15, r'mean = ' + str(n_scores.mean().round(6)) + '  '+ 'SD = ' + str(n_scores.std().round(6)))\nplt.xlim(0.9, 1.01)\nplt.xlabel('Acuuracy')\nplt.ylabel('Probability (%)')\nplt.grid(True)\nplt.show()\n\nmodel.fit(X_train,y_train)\nresult = permutation_importance(model, X_train, y_train, n_repeats=1000, random_state=42, n_jobs=2)\nprint('Permutation importance - average:'.format(), X_train.columns)\nprint([round(i, 6) for i in result.importances_mean])\n\n# displace feature importance\nfig, ax = plt.subplots(figsize=(6,5))\nax.boxplot(result.importances.T)\nax.set_title(\"Permutation Importances\", fontsize = 16)\nax.set_xticklabels(labels=X_train.columns, fontsize=14)\nplt.show()\n\n# save model \ndir_model = f\"{home_directory}/models/random_forest_SCA_binary.joblib\"\njoblib.dump(model, dir_model)",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/m2tvefpftuh/modeL-training.py\", line 3, in <module>\n    home_directory = os.path.expanduser('~')\nNameError: name 'os' is not defined\n",
  "history_begin_time" : 1717395658227,
  "history_end_time" : 1717395658713,
  "history_notes" : null,
  "history_process" : "8e59lt",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "gx9suj4of98",
  "history_input" : "import pandas as pd\n\n# read model input features and labels \ndata = pd.read_csv('./data/samples/sample_100K.csv', index_col = False)\nprint(\"Sample dimentions:\".format(), data.shape)\nprint(data.head())\nX = data[['blue','green','red','nir']]\ny = data['label']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.96,random_state=1)\n\n# define the model\nmodel = RandomForestClassifier(n_estimators=10, max_depth=10, max_features=4)\n\n# evaluate the model\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1000)\nn_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n# report model performance\nprint('Mean Score: %.6f (SD: %.6f)' % (n_scores.mean(),n_scores.std()))\n\n# the histogram of the scores\nn, bins, patches = plt.hist(n_scores, density=True, facecolor='blue', alpha=0.75)\nplt.text(0.91, 15, r'mean = ' + str(n_scores.mean().round(6)) + '  '+ 'SD = ' + str(n_scores.std().round(6)))\nplt.xlim(0.9, 1.01)\nplt.xlabel('Acuuracy')\nplt.ylabel('Probability (%)')\nplt.grid(True)\nplt.show()\n\nmodel.fit(X_train,y_train)\nresult = permutation_importance(model, X_train, y_train, n_repeats=1000, random_state=42, n_jobs=2)\nprint('Permutation importance - average:'.format(), X_train.columns)\nprint([round(i, 6) for i in result.importances_mean])\n\n# displace feature importance\nfig, ax = plt.subplots(figsize=(6,5))\nax.boxplot(result.importances.T)\nax.set_title(\"Permutation Importances\", fontsize = 16)\nax.set_xticklabels(labels=X_train.columns, fontsize=14)\nplt.show()\n\n# save model \ndir_model = \"./models/random_forest_SCA_binary.joblib\"\njoblib.dump(model, dir_model)",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/gx9suj4of98/modeL-training.py\", line 4, in <module>\n    data = pd.read_csv('./data/samples/sample_100K.csv', index_col = False)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 211, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 331, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 950, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 605, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1442, in __init__\n    self._engine = self._make_engine(f, self.engine)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1735, in _make_engine\n    self.handles = get_handle(\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 856, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: './data/samples/sample_100K.csv'\n",
  "history_begin_time" : 1717395606930,
  "history_end_time" : 1717395607497,
  "history_notes" : null,
  "history_process" : "8e59lt",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "e005wqu9bgp",
  "history_input" : "import pandas as pd\n\n# read model input features and labels \ndata = pd.read_csv('./data/samples/sample_100K.csv', index_col = False)\nprint(\"Sample dimentions:\".format(), data.shape)\nprint(data.head())\nX = data[['blue','green','red','nir']]\ny = data['label']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.96,random_state=1)\n\n# define the model\nmodel = RandomForestClassifier(n_estimators=10, max_depth=10, max_features=4)\n\n# evaluate the model\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1000)\nn_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n# report model performance\nprint('Mean Score: %.6f (SD: %.6f)' % (n_scores.mean(),n_scores.std()))\n\n# the histogram of the scores\nn, bins, patches = plt.hist(n_scores, density=True, facecolor='blue', alpha=0.75)\nplt.text(0.91, 15, r'mean = ' + str(n_scores.mean().round(6)) + '  '+ 'SD = ' + str(n_scores.std().round(6)))\nplt.xlim(0.9, 1.01)\nplt.xlabel('Acuuracy')\nplt.ylabel('Probability (%)')\nplt.grid(True)\nplt.show()\n\nmodel.fit(X_train,y_train)\nresult = permutation_importance(model, X_train, y_train, n_repeats=1000, random_state=42, n_jobs=2)\nprint('Permutation importance - average:'.format(), X_train.columns)\nprint([round(i, 6) for i in result.importances_mean])\n\n# displace feature importance\nfig, ax = plt.subplots(figsize=(6,5))\nax.boxplot(result.importances.T)\nax.set_title(\"Permutation Importances\", fontsize = 16)\nax.set_xticklabels(labels=X_train.columns, fontsize=14)\nplt.show()\n\n# save model \ndir_model = \"./models/random_forest_SCA_binary.joblib\"\njoblib.dump(model, dir_model)",
  "history_output" : "Traceback (most recent call last):\n  File \"modeL-training.py\", line 1, in <module>\n    import pandas as pd\nModuleNotFoundError: No module named 'pandas'\n",
  "history_begin_time" : 1679029191674,
  "history_end_time" : 1679029192832,
  "history_notes" : null,
  "history_process" : "8e59lt",
  "host_id" : "efrbpv",
  "indicator" : "Failed"
},{
  "history_id" : "09md2nv7tcp",
  "history_input" : "# read model input features and labels \ndata = pd.read_csv('./data/samples/sample_100K.csv', index_col = False)\nprint(\"Sample dimentions:\".format(), data.shape)\nprint(data.head())\nX = data[['blue','green','red','nir']]\ny = data['label']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.96,random_state=1)\n\n# define the model\nmodel = RandomForestClassifier(n_estimators=10, max_depth=10, max_features=4)\n\n# evaluate the model\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1000)\nn_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n# report model performance\nprint('Mean Score: %.6f (SD: %.6f)' % (n_scores.mean(),n_scores.std()))\n\n# the histogram of the scores\nn, bins, patches = plt.hist(n_scores, density=True, facecolor='blue', alpha=0.75)\nplt.text(0.91, 15, r'mean = ' + str(n_scores.mean().round(6)) + '  '+ 'SD = ' + str(n_scores.std().round(6)))\nplt.xlim(0.9, 1.01)\nplt.xlabel('Acuuracy')\nplt.ylabel('Probability (%)')\nplt.grid(True)\nplt.show()\n\nmodel.fit(X_train,y_train)\nresult = permutation_importance(model, X_train, y_train, n_repeats=1000, random_state=42, n_jobs=2)\nprint('Permutation importance - average:'.format(), X_train.columns)\nprint([round(i, 6) for i in result.importances_mean])\n\n# displace feature importance\nfig, ax = plt.subplots(figsize=(6,5))\nax.boxplot(result.importances.T)\nax.set_title(\"Permutation Importances\", fontsize = 16)\nax.set_xticklabels(labels=X_train.columns, fontsize=14)\nplt.show()\n\n# save model \ndir_model = \"./models/random_forest_SCA_binary.joblib\"\njoblib.dump(model, dir_model)",
  "history_output" : "Traceback (most recent call last):\n  File \"modeL-training.py\", line 2, in <module>\n    data = pd.read_csv('./data/samples/sample_100K.csv', index_col = False)\nNameError: name 'pd' is not defined\n",
  "history_begin_time" : 1679029164406,
  "history_end_time" : 1679029165343,
  "history_notes" : null,
  "history_process" : "8e59lt",
  "host_id" : "efrbpv",
  "indicator" : "Failed"
},{
  "history_id" : "9g5fp02mgzu",
  "history_input" : "# read model input features and labels \ndata = pd.read_csv('./data/samples/sample_100K.csv', index_col = False)\nprint(\"Sample dimentions:\".format(), data.shape)\nprint(data.head())\nX = data[['blue','green','red','nir']]\ny = data['label']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.96,random_state=1)\n\n# define the model\nmodel = RandomForestClassifier(n_estimators=10, max_depth=10, max_features=4)\n\n# evaluate the model\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1000)\nn_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n# report model performance\nprint('Mean Score: %.6f (SD: %.6f)' % (n_scores.mean(),n_scores.std()))\n\n# the histogram of the scores\nn, bins, patches = plt.hist(n_scores, density=True, facecolor='blue', alpha=0.75)\nplt.text(0.91, 15, r'mean = ' + str(n_scores.mean().round(6)) + '  '+ 'SD = ' + str(n_scores.std().round(6)))\nplt.xlim(0.9, 1.01)\nplt.xlabel('Acuuracy')\nplt.ylabel('Probability (%)')\nplt.grid(True)\nplt.show()\n\nmodel.fit(X_train,y_train)\nresult = permutation_importance(model, X_train, y_train, n_repeats=1000, random_state=42, n_jobs=2)\nprint('Permutation importance - average:'.format(), X_train.columns)\nprint([round(i, 6) for i in result.importances_mean])\n\n# displace feature importance\nfig, ax = plt.subplots(figsize=(6,5))\nax.boxplot(result.importances.T)\nax.set_title(\"Permutation Importances\", fontsize = 16)\nax.set_xticklabels(labels=X_train.columns, fontsize=14)\nplt.show()\n\n# save model \ndir_model = \"./models/random_forest_SCA_binary.joblib\"\njoblib.dump(model, dir_model)",
  "history_output" : "Traceback (most recent call last):\n  File \"modeL-training.py\", line 2, in <module>\n    data = pd.read_csv('./data/samples/sample_100K.csv', index_col = False)\nNameError: name 'pd' is not defined\n",
  "history_begin_time" : 1679029023864,
  "history_end_time" : 1679029024949,
  "history_notes" : null,
  "history_process" : "8e59lt",
  "host_id" : "efrbpv",
  "indicator" : "Failed"
},{
  "history_id" : "z3bm7innayk",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1717395177739,
  "history_notes" : null,
  "history_process" : "8e59lt",
  "host_id" : "100001",
  "indicator" : "Stopped"
},]
